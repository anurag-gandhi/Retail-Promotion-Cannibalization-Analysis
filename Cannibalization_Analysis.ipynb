{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read input files\n",
    "date_map = pd.read_csv('C:/Users/Anurag.Gandhi/Desktop/date_map.csv')\n",
    "promotions = pd.read_csv('C:/Users/Anurag.Gandhi/Desktop/hnp_promotions.csv')\n",
    "#read transaction data\n",
    "txn_data = pd.read_csv('C:/Users/Anurag.Gandhi/Desktop/txn_data_2_years.csv'\n",
    "                  ,encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txn_data['NEW_DATE'] = pd.to_datetime(txn_data['TRANSACTION_DATE'], format = '%d%b%Y')\n",
    "date_map['NEW_DATE'] = pd.to_datetime(date_map['CALENDAR_DATE'], format = '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txn_data = pd.merge(txn_data, date_map, how = 'left', on = 'NEW_DATE', sort = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txn_data.rename(columns = {'WEEK_NO': 'PROM_WEEK_NO'}, inplace = True)\n",
    "promotions.rename(columns = {'sku': 'SKU', 'prom_week_no': 'PROM_WEEK_NO'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txn_data = pd.merge(txn_data, promotions[promotions['zone_id'] == 5][['SKU', 'PROM_WEEK_NO', 'promotions', 'promotions_NC']], \n",
    "                 how = 'left', on = ['SKU', 'PROM_WEEK_NO'], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txn_data[['promotions','promotions_NC']] = txn_data[['promotions','promotions_NC']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Unique ID for Customer-Day (proxy for transaction)\n",
    "txn_data['UNIQUE_CUST_TRANS'] = txn_data['INFERRED_CUSTOMER_ID'].map(str) + txn_data['TRANSACTION_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read correlation output\n",
    "sisters_list = pd.read_csv('H:/Depository/Sirsa/Promotion_Analytics/Research/Anurag/Basket/sisters_corr_hnp_v3.csv',encoding = \"ISO-8859-1\")\n",
    "\n",
    "#business inputs \n",
    "#sisters_list = pd.DataFrame(sisters_list[sisters_list['buyer_id_2'].isin([4494,4266,4502])]).reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sisters_list_corr = sisters_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift (X->Y) = confidence(X->Y) / support(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_sku = txn_data[['UNIQUE_CUST_TRANS','SKU','PROM_WEEK_NO']].drop_duplicates()\n",
    "#loop for each combination\n",
    "start_time = time.time()\n",
    "for i in range(0,len(sisters_list)):\n",
    "#for i in range(0,363):\n",
    "    #SKU A: Dishwash SKU\n",
    "    SKU_A = sisters_list.ix[i,'SKU_1']\n",
    "    \n",
    "    #SKU B: Sister SKU\n",
    "    SKU_B = sisters_list.ix[i,'SKU_2']\n",
    "    \n",
    "    #filter weeks where only ONE of the products was on promotion\n",
    "    test = txn_data[txn_data['SKU'].isin([SKU_A,SKU_B])][['PROM_WEEK_NO', 'promotions', 'SKU']].drop_duplicates()\n",
    "    test_2 = test.pivot(index = 'PROM_WEEK_NO', columns = 'SKU', values = 'promotions').fillna(0)\n",
    "    test_2['sum'] = test_2[SKU_A] + test_2[SKU_B]\n",
    "    test_2['product'] = test_2[SKU_A] * test_2[SKU_B]\n",
    "    prom_week_list = test_2[(test_2['sum'] > 0) & (test_2['product'] == 0)].index.values\n",
    "    \n",
    "    #Customers who bought these two SKUs:\n",
    "    hnp_pair = txn_data[txn_data['SKU'].isin([SKU_A,SKU_B])][['INFERRED_CUSTOMER_ID', 'SKU']].drop_duplicates()\n",
    "    sku_count_by_customer = hnp_pair.groupby( ['INFERRED_CUSTOMER_ID'], sort = False).count()\n",
    "    \n",
    "    #ATLEAST 1 customer should have bought both the products (this removes unrelated products)\n",
    "    if ((max(sku_count_by_customer['SKU']) > 1) & (len(prom_week_list) > 0 )):\n",
    "        \n",
    "        #distinct SKU transactions\n",
    "        trans_sku_pair = trans_sku[trans_sku['PROM_WEEK_NO'].isin(prom_week_list)][['UNIQUE_CUST_TRANS','SKU']]\n",
    "        trans_sku_pair = trans_sku_pair[trans_sku_pair['SKU'].isin([SKU_A,SKU_B])].drop_duplicates()\n",
    "        pivoted = trans_sku_pair.groupby( ['UNIQUE_CUST_TRANS'], sort = False).count()\n",
    "        \n",
    "        #Support (A) = number/fraction of transactions with A\n",
    "        support_a = trans_sku_pair[trans_sku_pair['SKU'] == SKU_A].shape[0]\n",
    "        \n",
    "        #Suport (B) = number/fraction of transactions with B\n",
    "        support_b = trans_sku_pair[trans_sku_pair['SKU'] == SKU_B ].shape[0]\n",
    "        \n",
    "        #Support (A, B) = number/fraction of transactions with both A & B\n",
    "        intersection = pivoted[pivoted['SKU'] == 2].shape[0]\n",
    "        sisters_list.ix[i,'SUPPORT A'] = support_a\n",
    "        sisters_list.ix[i,'SUPPORT B'] = support_b\n",
    "        sisters_list.ix[i,'SUPPORT A_B'] = intersection\n",
    "        \n",
    "        #Confidence = Support (A, B) / Support (A)\n",
    "        sisters_list.ix[i,'CONFIDENCE'] = np.float64(intersection)/support_a\n",
    "        \n",
    "        #Lift = Support (A, B) / ( Support (A) * Support (B) )\n",
    "        sisters_list.ix[i,'LIFT'] = np.float64(intersection)/(support_a*support_b)\n",
    "    else:\n",
    "        sisters_list.ix[i,'LIFT'] = 1000\n",
    "    print (i + 1, \" of\", len(sisters_list), \" done.\")\n",
    "end_time = time.time()\n",
    "print (\"Elapsed Time:\",(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sisters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sisters_list[sisters_list['sub_category_2'] == 417]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = sisters_list[['SKU_1','sku_desc_1', 'sub_category_name_1', 'SKU_2', 'sku_desc_2', 'sub_category_name_2', \n",
    "                        'SUPPORT A', 'SUPPORT B', 'SUPPORT A_B', 'CONFIDENCE', 'LIFT', 'count_stores', 'base', 'avg_corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sisters_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[(results['LIFT'] < 3e-7) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_0_lift = results[ (results['LIFT'] < 1e-6) & (results['SUPPORT A'] >= 300) & (results['SUPPORT B'] >=300) ]\n",
    "results_0_lift['SKU_1'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_0_lift.to_csv('results_dishwash_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_0_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SKU_A = 7512416\n",
    "SKU_B = 2947365\n",
    "hnp_pair = hnp[hnp['SKU'].isin([SKU_A,SKU_B])][['INFERRED_CUSTOMER_ID', 'SKU']].drop_duplicates()\n",
    "sku_count_by_customer = hnp_pair.groupby( ['INFERRED_CUSTOMER_ID']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customer_list = sku_count_by_customer[sku_count_by_customer['SKU'] == 2].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pair = hnp[hnp['SKU'].isin([SKU_A,SKU_B]) & (hnp['INFERRED_CUSTOMER_ID'].isin(customer_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SKU_list = [7512240, 2947365, 7495079, 7512244, 7512320, 7512370, 7512427, 7624019]\n",
    "txn_test = txn_data[txn_data['SKU'].isin(SKU_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_sisters(row):\n",
    "    if row['SKU'] == 7512240:\n",
    "        return 'Parent'\n",
    "    else:\n",
    "        return 'Sister'\n",
    "\n",
    "txn_test['Status'] = txn_test.apply(classify_sisters, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txn_test.to_csv('boundary_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txn_data[(txn_data['INFERRED_CUSTOMER_ID'] == 40000977860936) & (txn_data['SKU'] == 7512242)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sisters_list[(sisters_list['SKU_1'] == 7512240) & (sisters_list['SKU_2'] == 7512242)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
